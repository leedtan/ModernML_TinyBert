{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebookversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySh1iYWIQMzN",
        "outputId": "850f243b-5b87-4d16-e837-ef2c6a50be07"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yc320aO8Yq5",
        "outputId": "09090925-ec08-49d4-fecf-cd1940587fff"
      },
      "source": [
        "pip install gspread==3.6\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread==3.6 in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (0.4.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (1.17.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread==3.6) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XimlS4I8e3_"
      },
      "source": [
        "\r\n",
        "\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "\r\n",
        "def get_next_row():\r\n",
        "  current_max_row = len(sheet.get_all_values())\r\n",
        "  new_row_to_append = int(current_max_row) + 1\r\n",
        "  return f\"A{new_row_to_append}\"\r\n",
        "\r\n",
        "row = get_next_row()\r\n",
        "sheet.update(row, [['blah', 'Lee']])\r\n",
        "current_max_row = max(sheet.get_all_records()[0].keys())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXWzpoC96RZp",
        "outputId": "91057fff-32c6-41bc-9835-961fbf532979"
      },
      "source": [
        "from psutil import virtual_memory\r\n",
        "ram_gb = virtual_memory().total / 1e9\r\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\r\n",
        "\r\n",
        "if ram_gb < 20:\r\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\r\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\r\n",
        "  print('re-execute this cell.')\r\n",
        "else:\r\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmHI50DQURSm"
      },
      "source": [
        "# pip install df2gspread"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18eNh6ZKUPZU"
      },
      "source": [
        "\r\n",
        "# from df2gspread import df2gspread as d2g\r\n",
        "# import pandas as pd\r\n",
        "# d = [pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\r\n",
        "#     pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])]\r\n",
        "# df = pd.DataFrame(d)\r\n",
        "\r\n",
        "# # use full path to spreadsheet file\r\n",
        "# spreadsheet = '/some/folder/New Spreadsheet'\r\n",
        "# # or spreadsheet file id\r\n",
        "# # spreadsheet = '1cIOgi90...'\r\n",
        "\r\n",
        "# wks_name = 'New Sheet'\r\n",
        "\r\n",
        "# d2g.upload(df, spreadsheet, wks_name)\r\n",
        "# # if spreadsheet already exists, all data of provided worksheet(or first as default)\r\n",
        "# # will be replaced with data of given DataFrame, make sure that this is what you need!"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o6YhB5f_Vw7"
      },
      "source": [
        "\r\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "# !pip install gputil\r\n",
        "# !pip install psutil\r\n",
        "# !pip install humanize\r\n",
        "# import psutil\r\n",
        "# import humanize\r\n",
        "# import os\r\n",
        "# import GPUtil as GPU\r\n",
        "# GPUs = GPU.getGPUs()\r\n",
        "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\r\n",
        "# gpu = GPUs[0]\r\n",
        "# def printm():\r\n",
        "#  process = psutil.Process(os.getpid())\r\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "# printm()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOjlJL05VnYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3303fba-af2d-48ed-b058-4bbb299f8183"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "sheet.update('A1', [[1, 2], [3, 4]])\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg',\n",
              " 'updatedCells': 4,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedRange': 'results!A1:B2',\n",
              " 'updatedRows': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-6MMqgDf2dX",
        "outputId": "296733e7-60e8-495a-a09a-9d3627bb0097"
      },
      "source": [
        "%%writefile setup.sh\r\n",
        "\r\n",
        "git clone https://github.com/NVIDIA/apex\r\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjAPAUvOS_3"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOveHVPtNd9G",
        "outputId": "436dbc8f-e1d5-4fab-8421-768e97c812ec"
      },
      "source": [
        "\r\n",
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data  setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2HhzoBPZml"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8t29tIHf31h"
      },
      "source": [
        "\r\n",
        "# import os\r\n",
        "# if not os.path.isdir('drive'):\r\n",
        "#   os.mkdir('drive')\r\n",
        "# os.chdir('drive')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdAs8j21N9ie",
        "outputId": "bab52d29-d7fd-4633-9f91-a0f40c82fcb6"
      },
      "source": [
        "%cd drive/My Drive/mixout/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mixout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ha8_oPIOWxL",
        "outputId": "103ba077-e217-4091-9d91-ea3fec069f25"
      },
      "source": [
        "\r\n",
        "!pwd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mixout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSihpO2UB3KB",
        "outputId": "943e91c2-9b56-41f8-ba5c-3f418cd0bb59"
      },
      "source": [
        "!git clone https://github.com/leedtan/ModernML_TinyBert.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ModernML_TinyBert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rhEPAgKB6Rs",
        "outputId": "05aa7696-98f7-4798-dc8d-0f90bbb4f000"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "os.listdir()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ModernML_TinyBert']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbXC3ftfCG5b",
        "outputId": "e7c939c3-916f-401d-beef-ebbb5a759395"
      },
      "source": [
        "os.chdir('ModernML_TinyBert')\r\n",
        "!python download_glue_data.py"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n",
            "Processing MRPC...\n",
            "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
            "\tCompleted!\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "Downloading and extracting STS...\n",
            "\tCompleted!\n",
            "Downloading and extracting MNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting SNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting QNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting RTE...\n",
            "\tCompleted!\n",
            "Downloading and extracting WNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting diagnostic...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1tgNjIBSj-e"
      },
      "source": [
        "# import gspread\r\n",
        "# gc = gspread.service_account()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6v64IffA-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5197138e-3adb-4b12-a9a6-0294ba1ed979"
      },
      "source": [
        "\r\n",
        "os.chdir('revisit-bert-finetuning')\r\n",
        "os.listdir()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LICENSE',\n",
              " 'model_utils.py',\n",
              " 'prior_wd_optim.py',\n",
              " 'repo_illustration.png',\n",
              " 'requirements.txt',\n",
              " 'sample_commands',\n",
              " '__init__.py',\n",
              " 'emily_run_glue_experiment.sh',\n",
              " 'finetuning_torchvision_models_tutorial.ipynb',\n",
              " 'mixout-fan-in.ipynb',\n",
              " 'mixout.ipynb',\n",
              " 'run_glue_datasets.py',\n",
              " 'run_glue_experiment.py',\n",
              " 'ryan.sh',\n",
              " 'ryan_run_glue_experiment.sh',\n",
              " 'summarize_results.py',\n",
              " '__pycache__',\n",
              " 'README.md',\n",
              " 'mixout.py',\n",
              " 'run_glue.py',\n",
              " 'options.py']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMpPx5qVbtxo",
        "outputId": "3c4d0163-5859-450e-871a-bb9b1e21080a"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.16.40)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.94)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.19.4)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.19.40)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.40->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4ze4fDiwly",
        "outputId": "2a550c7f-0681-4a96-edd5-8bffff6bb86a"
      },
      "source": [
        "!git checkout some_frozen_mixout_reg_scaling"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M\tdownload_wiki_dump.sh\n",
            "M\textract_and_clean_wiki_dump.sh\n",
            "M\trevisit-bert-finetuning/emily_run_glue_experiment.sh\n",
            "Already on 'some_frozen_mixout_reg_scaling'\n",
            "Your branch is up to date with 'origin/some_frozen_mixout_reg_scaling'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNcDJBD4ljpx",
        "outputId": "67ce35f4-2a34-451b-b763-8ae136d4cf31"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emily_run_glue_experiment.sh\t\t      README.md\n",
            "finetuning_torchvision_models_tutorial.ipynb  repo_illustration.png\n",
            "__init__.py\t\t\t\t      requirements.txt\n",
            "LICENSE\t\t\t\t\t      run_glue_datasets.py\n",
            "mixout-fan-in.ipynb\t\t\t      run_glue_experiment.py\n",
            "mixout.ipynb\t\t\t\t      run_glue.py\n",
            "mixout.py\t\t\t\t      ryan_run_glue_experiment.sh\n",
            "model_utils.py\t\t\t\t      ryan.sh\n",
            "options.py\t\t\t\t      sample_commands\n",
            "prior_wd_optim.py\t\t\t      summarize_results.py\n",
            "__pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc9De3PNlEAI",
        "outputId": "c494b2ad-5cc2-4981-b155-0444ab751f8f"
      },
      "source": [
        "!cat ryan.sh"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "    --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "    --output_dir tests/FULLTESTS/decay_50_to_20 \\\n",
            "    --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "    --trials 20 --mixout_decay 0.5\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/decay_90_to_20 \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "#     --trials 20 --mixout_decay 0.9\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10\n",
            "    \n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSNnAAAsyMS",
        "outputId": "354e07e9-c778-42fb-bfee-8d5f34e544e5"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/19)\u001b[K\rremote: Counting objects:  10% (2/19)\u001b[K\rremote: Counting objects:  15% (3/19)\u001b[K\rremote: Counting objects:  21% (4/19)\u001b[K\rremote: Counting objects:  26% (5/19)\u001b[K\rremote: Counting objects:  31% (6/19)\u001b[K\rremote: Counting objects:  36% (7/19)\u001b[K\rremote: Counting objects:  42% (8/19)\u001b[K\rremote: Counting objects:  47% (9/19)\u001b[K\rremote: Counting objects:  52% (10/19)\u001b[K\rremote: Counting objects:  57% (11/19)\u001b[K\rremote: Counting objects:  63% (12/19)\u001b[K\rremote: Counting objects:  68% (13/19)\u001b[K\rremote: Counting objects:  73% (14/19)\u001b[K\rremote: Counting objects:  78% (15/19)\u001b[K\rremote: Counting objects:  84% (16/19)\u001b[K\rremote: Counting objects:  89% (17/19)\u001b[K\rremote: Counting objects:  94% (18/19)\u001b[K\rremote: Counting objects: 100% (19/19)\u001b[K\rremote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)\u001b[K\rremote: Compressing objects:  40% (2/5)\u001b[K\rremote: Compressing objects:  60% (3/5)\u001b[K\rremote: Compressing objects:  80% (4/5)\u001b[K\rremote: Compressing objects: 100% (5/5)\u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 14 (delta 9), reused 14 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects:   7% (1/14)   \rUnpacking objects:  14% (2/14)   \rUnpacking objects:  21% (3/14)   \rUnpacking objects:  28% (4/14)   \rUnpacking objects:  35% (5/14)   \rUnpacking objects:  42% (6/14)   \rUnpacking objects:  50% (7/14)   \rUnpacking objects:  57% (8/14)   \rUnpacking objects:  64% (9/14)   \rUnpacking objects:  71% (10/14)   \rUnpacking objects:  78% (11/14)   \rUnpacking objects:  85% (12/14)   \rUnpacking objects:  92% (13/14)   \rUnpacking objects: 100% (14/14)   \rUnpacking objects: 100% (14/14), done.\n",
            "From https://github.com/leedtan/ModernML_TinyBert\n",
            "   9f7214b..4db0781  some_frozen_mixout_reg_scaling -> origin/some_frozen_mixout_reg_scaling\n",
            "Updating 9f7214b..4db0781\n",
            "Fast-forward\n",
            " revisit-bert-finetuning/glue_utils.py        | 225 \u001b[32m+++++++\u001b[m\n",
            " revisit-bert-finetuning/manipulate_model.py  | 122 \u001b[32m++++\u001b[m\n",
            " revisit-bert-finetuning/options.py           |  27 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " revisit-bert-finetuning/run_glue.py          | 893 \u001b[32m+\u001b[m\u001b[31m--------------------------\u001b[m\n",
            " revisit-bert-finetuning/run_glue_datasets.py |  31 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " revisit-bert-finetuning/train.py             | 501 \u001b[32m+++++++++++++++\u001b[m\n",
            " revisit-bert-finetuning/validate.py          | 125 \u001b[32m++++\u001b[m\n",
            " 7 files changed, 1047 insertions(+), 877 deletions(-)\n",
            " create mode 100644 revisit-bert-finetuning/glue_utils.py\n",
            " create mode 100644 revisit-bert-finetuning/manipulate_model.py\n",
            " create mode 100644 revisit-bert-finetuning/train.py\n",
            " create mode 100644 revisit-bert-finetuning/validate.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMmyARZeahpj"
      },
      "source": [
        "# !echo '''python run_glue_datasets.py \\\r\n",
        "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "#     --do_train --data_dir /content/ModernML_TinyBert/glue_data/RTE --max_seq_length 16 \\\r\n",
        "#     --per_gpu_eval_batch_size 64 --weight_decay 0 --seed 0 \\\r\n",
        "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 32 \\\r\n",
        "#     --gradient_accumulation_steps 1 --logging_steps 0 --num_loggings 10 \\\r\n",
        "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /content/ModernML_TinyBert/hf-transformers-cache \\\r\n",
        "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "#     --output_dir bert_output/REINIT5/RTE/SEED0 \\\r\n",
        "#     --reinit_pooler --reinit_layers 5''' > sample_commands/run.sh\r\n",
        "\r\n",
        "!echo '''python run_glue_datasets.py \\\r\n",
        "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "    --do_train --data_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\" --max_seq_length 64 \\\r\n",
        "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\r\n",
        "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\r\n",
        "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\r\n",
        "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" \\\r\n",
        "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "    --output_dir tests/FULLTESTS/classic --all_datasets \\\r\n",
        "    --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\r\n",
        "    --trials 10''' > sample_commands/run.sh"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJjWX1NsPYg2",
        "outputId": "3b770b54-2d94-46eb-cba7-6eb9ced963aa"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/leedtan/ModernML_TinyBert\n",
            "   8e6771e..3524de5  some_frozen_mixout_reg_scaling -> origin/some_frozen_mixout_reg_scaling\n",
            "Updating 8e6771e..3524de5\n",
            "Fast-forward\n",
            " revisit-bert-finetuning/options.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " revisit-bert-finetuning/train.py   | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 3 insertions(+), 3 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLlHIloufYic",
        "outputId": "2ffbc120-0d0f-4e55-ee07-da0d45d1d1ee"
      },
      "source": [
        "!sh sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-21 17:01:56.501076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/21/2020 17:01:58 - WARNING - run_glue -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/21/2020 17:01:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/21/2020 17:01:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/21/2020 17:01:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/21/2020 17:01:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"rte\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/21/2020 17:02:00 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/21/2020 17:02:00 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/21/2020 17:02:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/21/2020 17:02:00 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "12/21/2020 17:02:16 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "12/21/2020 17:02:16 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/21/2020 17:02:22 - INFO - run_glue -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, all_datasets=True, cache_dir='/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache', config_name='', data_dir='/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data/RTE', device=device(type='cuda'), do_lower_case=True, do_train=True, downsample_trainset=-1, finetune_layers=0, fp16=False, fp16_opt_level='O1', frozen_layers=0, gradient_accumulation_steps=4, l2_reg_decay=1.0, l2_reg_mult=0.003, l2_scaling=False, layer_mixout=False, layerwise_learning_rate_decay=1.0, learning_rate=2e-05, local_rank=-1, logging_steps=0, max_grad_norm=1.0, max_seq_length=64, max_steps=-1, mixout=0.3, mixout_decay=1.0, mixout_layers=12, model_name_or_path='bert-large-uncased', model_type='bert', n_gpu=1, no_cuda=False, normalize=True, num_loggings=10, num_train_epochs=3.0, output_dir='tests/FULLTESTS/classic_DATASET_rte_SEED_0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, prior_weight_decay=False, reinit_layers=0, reinit_pooler=True, resplit_val=0, rezero_layers=0, save_best=False, save_last=False, save_steps=0, seed=0, server_ip='', server_port='', task_name='rte', test_val_split=True, tokenizer_name='', train_batch_size=0, trials=10, unfreeze_after_epoch=0, use_bertadam=False, use_torch_adamw=True, warmup_ratio=0.1, warmup_steps=0, weight_decay=0.0, weight_logging_steps=10)\n",
            "12/21/2020 17:02:22 - INFO - run_glue -   Loading features from cached file /content/drive/My Drive/mixout/ModernML_TinyBert/glue_data/RTE/cached_train_bert-large-uncased_64_rte\n",
            "12/21/2020 17:02:22 - INFO - run_glue -   Loading features from cached file /content/drive/My Drive/mixout/ModernML_TinyBert/glue_data/RTE/cached_dev_bert-large-uncased_64_rte\n",
            "12/21/2020 17:02:22 - INFO - run_glue -   ***** Running training *****\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Num examples = 2490\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Num Epochs = 3\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Instantaneous batch size per GPU = 8\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Gradient Accumulation steps = 4\n",
            "12/21/2020 17:02:22 - INFO - run_glue -     Total optimization steps = 234\n",
            "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
            "iteration:   0% 0/312 [00:00<?, ?it/s]\u001b[A\n",
            " unfreezing mixout layers \n",
            "\n",
            "\n",
            "iteration:   0% 1/312 [00:05<29:44,  5.74s/it]\u001b[A\n",
            "iteration:   1% 2/312 [00:11<29:09,  5.64s/it]\u001b[A\n",
            "iteration:   1% 3/312 [00:16<28:41,  5.57s/it]\u001b[A\n",
            "iteration:   1% 4/312 [00:22<29:03,  5.66s/it]\u001b[A\n",
            "iteration:   2% 5/312 [00:27<28:48,  5.63s/it]\u001b[A\n",
            "iteration:   2% 6/312 [00:33<28:25,  5.57s/it]\u001b[A\n",
            "iteration:   2% 7/312 [00:38<28:03,  5.52s/it]\u001b[A\n",
            "iteration:   3% 8/312 [00:44<28:08,  5.55s/it]\u001b[A\n",
            "iteration:   3% 9/312 [00:49<27:32,  5.46s/it]\u001b[A\n",
            "iteration:   3% 10/312 [00:55<27:20,  5.43s/it]\u001b[A\n",
            "iteration:   4% 11/312 [01:00<27:12,  5.42s/it]\u001b[A\n",
            "iteration:   4% 12/312 [01:05<27:12,  5.44s/it]\u001b[A\n",
            "iteration:   4% 13/312 [01:11<27:30,  5.52s/it]\u001b[A\n",
            "iteration:   4% 14/312 [01:17<27:14,  5.49s/it]\u001b[A\n",
            "iteration:   5% 15/312 [01:22<27:15,  5.51s/it]\u001b[A\n",
            "iteration:   5% 16/312 [01:28<27:12,  5.51s/it]\u001b[A\n",
            "iteration:   5% 17/312 [01:33<27:05,  5.51s/it]\u001b[A\n",
            "iteration:   6% 18/312 [01:38<26:42,  5.45s/it]\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nLTvP3azsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}