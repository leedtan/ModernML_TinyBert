{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c13565e99d8469494a7ea679f0a772f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88358b930a45426ea66d22c44b22810d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3e89bba2ce74511b7fdd8001e8bb3d7",
              "IPY_MODEL_99040e9f32f9488cab5800d64a2b13f8"
            ]
          }
        },
        "88358b930a45426ea66d22c44b22810d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3e89bba2ce74511b7fdd8001e8bb3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f91674bc38c34e4b9eb628689310c607",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a2612b2825a4b238cbd4115a6675fb2"
          }
        },
        "99040e9f32f9488cab5800d64a2b13f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89eaea86a8da4700b37eae598cdfa44f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 16.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8963017b9374008882526b484ba26e1"
          }
        },
        "f91674bc38c34e4b9eb628689310c607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a2612b2825a4b238cbd4115a6675fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89eaea86a8da4700b37eae598cdfa44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8963017b9374008882526b484ba26e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySh1iYWIQMzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe7055c-3e3c-463c-cb47-5d57bc883b6d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yc320aO8Yq5",
        "outputId": "704f02f7-f482-4219-be4d-1dce17eb50bb"
      },
      "source": [
        "pip install gspread==3.6\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread==3.6 in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (0.4.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (1.17.2)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (51.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.12.0->gspread==3.6) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XimlS4I8e3_"
      },
      "source": [
        "import numpy as np\r\n",
        "import pdb\r\n",
        "import pandas as pd\r\n",
        "import numbers\r\n",
        "from google.colab import auth\r\n",
        "import os\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXWzpoC96RZp"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-6MMqgDf2dX",
        "outputId": "f261fbe7-46ff-4392-caf8-09ce52c3fc3e"
      },
      "source": [
        "%%writefile setup.sh\r\n",
        "\r\n",
        "git clone https://github.com/NVIDIA/apex\r\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjAPAUvOS_3"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAs8j21N9ie"
      },
      "source": [
        "# %cd drive/My Drive/mixout/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSihpO2UB3KB",
        "outputId": "9fae9e35-16b1-4884-8e6c-fd9653eec87a"
      },
      "source": [
        "!git clone https://github.com/leedtan/ModernML_TinyBert.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ModernML_TinyBert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbXC3ftfCG5b",
        "outputId": "0d0bb1df-1f37-4f4e-e109-8e845a6beea6"
      },
      "source": [
        "os.chdir('ModernML_TinyBert')\r\n",
        "# !python download_glue_data.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting CoLA...\n",
            "Traceback (most recent call last):\n",
            "  File \"download_glue_data.py\", line 141, in <module>\n",
            "    sys.exit(main(sys.argv[1:]))\n",
            "  File \"download_glue_data.py\", line 137, in main\n",
            "    download_and_extract(task, args.data_dir)\n",
            "  File \"download_glue_data.py\", line 47, in download_and_extract\n",
            "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 248, in urlretrieve\n",
            "    with contextlib.closing(urlopen(url, data)) as fp:\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 532, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
            "    'http', request, response, code, msg, hdrs)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 570, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 403: Forbidden\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6v64IffA-m"
      },
      "source": [
        "os.chdir('revisit-bert-finetuning')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMpPx5qVbtxo",
        "outputId": "4321d2da-323b-42e7-cc21-1ed6e05fbc72"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.94)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.16.47)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.19.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.47->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4ze4fDiwly",
        "outputId": "d1444975-db8f-491a-992b-91e7c7bc4a19"
      },
      "source": [
        "!git checkout some_frozen_mixout_reg_scaling"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already on 'some_frozen_mixout_reg_scaling'\n",
            "Your branch is up to date with 'origin/some_frozen_mixout_reg_scaling'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc9De3PNlEAI",
        "outputId": "2acaf8c0-a61d-480f-8fd9-4cc211f8aa1e"
      },
      "source": [
        "!cat ryan.sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "    --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "    --output_dir tests/FULLTESTS/decay_50_to_20 \\\n",
            "    --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "    --trials 20 --mixout_decay 0.5\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/decay_90_to_20 \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "#     --trials 20 --mixout_decay 0.9\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10\n",
            "    \n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSNnAAAsyMS",
        "outputId": "d2b4687f-0ff9-4da2-dad2-483db7ff3308"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kea-k7zqs5"
      },
      "source": [
        "\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "def get_df(sheet):\r\n",
        "  df = pd.DataFrame(sheet.get_all_values())\r\n",
        "  df.columns = df.iloc[0,:]\r\n",
        "  df.index = df.iloc[:,0]\r\n",
        "  df = df.iloc[1:,1:]\r\n",
        "  return df\r\n",
        "  \r\n",
        "def get_row_num(df, sheet, paramnames):\r\n",
        "  if paramnames in df.index:\r\n",
        "    rowidx = df.index.to_list().index(paramnames) + 1\r\n",
        "  else:\r\n",
        "    current_max_row = len(sheet.get_all_values())\r\n",
        "    rowidx = int(current_max_row) + 1\r\n",
        "  return rowidx\r\n",
        "def check_run(paramnames, task, df = None, sheet = None):\r\n",
        "  if 1:# df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  if paramnames in df.index:\r\n",
        "    idx = df.columns.to_list().index(task)\r\n",
        "    row = df.loc[paramnames,:]\r\n",
        "    rowiloc = row.iloc[idx+1]\r\n",
        "    if rowiloc == '':\r\n",
        "      return True\r\n",
        "    if not isinstance(rowiloc, numbers.Number):\r\n",
        "      if isinstance(rowiloc, str) and rowiloc.isnumeric():\r\n",
        "        rowiloc = int(rowiloc)\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "    if rowiloc >= 20:\r\n",
        "      return False\r\n",
        "  return True\r\n",
        "def run(paramnames, task, df, sheet, params = {}):\r\n",
        "  df = get_df(sheet)\r\n",
        "  if paramnames not in df.index:\r\n",
        "    row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "    sheet.update(f\"A{row_idx}\", [[paramnames]])\r\n",
        "    df = get_df(sheet)\r\n",
        "  row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "  df = get_df(sheet)\r\n",
        "  idx = df.columns.to_list().index(task)\r\n",
        "  count = df.iloc[row_idx-1, idx+1]\r\n",
        "  if count == '':\r\n",
        "    count = 0\r\n",
        "    avg = 0\r\n",
        "  avg = df.iloc[row_idx-1, idx]\r\n",
        "  if avg == '':\r\n",
        "    avg = 0\r\n",
        "  avg = float(avg)\r\n",
        "  count = int(count)\r\n",
        "  \r\n",
        "  all_datasets = ['rte','sts-b','mrpc','cola']\r\n",
        "  metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc']\r\n",
        "  metrics = dict(zip(all_datasets, metrics))\r\n",
        "  result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "  args.seed = seed = count + 1\r\n",
        "  args.output_dir = (\r\n",
        "      output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "  )\r\n",
        "  results = run_glue_main(args)\r\n",
        "  print(type(results))\r\n",
        "  print(results)\r\n",
        "  score = results['acc']\r\n",
        "  print('avg',type(avg),avg,'count',type(count),count,'score',type(score),score,)\r\n",
        "  newavg = (avg * count + score) / (count + 1)\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 2)}{row_idx+1}\", [[count+1]])\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 1)}{row_idx+1}\", [[newavg]])\r\n",
        "\r\n",
        "  return True\r\n",
        "def simulate(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < 20:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ_Zpy55Reav",
        "outputId": "2d932ff8-824a-4b58-9400-21ccb5fbcc08"
      },
      "source": [
        "def dict2obj(d):\r\n",
        "    if isinstance(d, list):\r\n",
        "        d = [dict2obj(x) for x in d]\r\n",
        "    if not isinstance(d, dict):\r\n",
        "        return d\r\n",
        "    class C(object):\r\n",
        "        def __init__(self):\r\n",
        "          pass\r\n",
        "        def __call__(self):\r\n",
        "          pass\r\n",
        "        pass\r\n",
        "    o = C()\r\n",
        "    for k in d:\r\n",
        "        o.__dict__[k] = dict2obj(d[k])\r\n",
        "    return o\r\n",
        "dict2obj({'b':2}).b"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz817xVTxL9"
      },
      "source": [
        "args ={'model_type': 'bert', 'model_name_or_path': 'bert-large-uncased', 'task_name': 'RTE', \r\n",
        "    'do_train':True, 'data_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\", 'max_seq_length': 64, \r\n",
        "    'per_gpu_eval_batch_size': 8, 'weight_decay': 0, 'seed': 1, \r\n",
        "    'overwrite_output_dir':True, 'do_lower_case':True, 'per_gpu_train_batch_size': 8, \r\n",
        "    'gradient_accumulation_steps': 4, 'logging_steps': 0, 'num_loggings': 10, \r\n",
        "    'save_steps': 0, 'test_val_split':True, 'use_torch_adamw':True, \r\n",
        "    'cache_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" ,\r\n",
        "    'num_train_epochs': 3.0, 'warmup_ratio': 0.1, 'learning_rate': 2e-05 ,\r\n",
        "    'output_dir': 'tests/FULLTESTS/classic', 'all_datasets':True, \r\n",
        "    'reinit_pooler': True, 'normalize': True, 'mixout_layers': 12, 'mixout': .3, \r\n",
        "    'trials': 10}\r\n",
        "\r\n",
        "for name, default_val in zip([\"data_dir\", \"model_type\", \"model_name_or_path\", \"task_name\", \"output_dir\",\r\n",
        " \"config_name\", \"tokenizer_name\", \"cache_dir\", \"max_seq_length\", \"do_train\",\"do_lower_case\", \"save_best\",\r\n",
        "  \"save_last\", \"train_batch_size\", \"per_gpu_train_batch_size\", \"per_gpu_eval_batch_size\", \"gradient_accumulation_steps\",\r\n",
        "   \"learning_rate\", \"layerwise_learning_rate_decay\", \"weight_decay\", \"adam_epsilon\", \"max_grad_norm\", \"num_train_epochs\", \r\n",
        "   \"max_steps\", \"warmup_steps\", \"warmup_ratio\", \"weight_logging_steps\", \"logging_steps\", \"num_loggings\", \"save_steps\", \r\n",
        "   \"no_cuda\",\"overwrite_output_dir\", \"overwrite_cache\", \"seed\", \"fp16\", \"fp16_opt_level\", \"local_rank\", \"server_ip\",\r\n",
        "   \"server_port\",\"use_bertadam\",\"use_torch_adamw\",\"downsample_trainset\", \"resplit_val\", \"reinit_layers\", \"mixout_layers\",\r\n",
        "    \"unfreeze_after_epoch\", \"reinit_pooler\",\"l2_scaling\",\"normalize\",\"all_datasets\",\"layer_mixout\",\"rezero_layers\", \"mixout\",\r\n",
        "     \"mixout_decay\", \"trials\", \"prior_weight_decay\", \"test_val_split\",'frozen_layers', 'finetune_layers',\r\n",
        "      'l2_reg_decay', 'l2_reg_mult'], \r\n",
        "      [None, None, None, None, None, '', '', '', 128, False, False, False, False, 0, 8, 8,\r\n",
        "1, 5e-5, 1.0, 0.0, 1e-8, 1.0, 3.0, -1, 0, 0, 10, 0, 0, 500, False, False, False, 42,\r\n",
        "False, '01', -1, '', '', False, False, -1, 0, 0, 0, 0, False, False, False, False, False, \r\n",
        "0, 0.0, 1.0, 20, False, False, 0, 0, 1.0, 3e-3]):\r\n",
        "    if name not in args:\r\n",
        "        args[name] = default_val"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wwaXBqycg8mG",
        "outputId": "5aa9948a-aada-4cc5-bac2-b9d992f7580f"
      },
      "source": [
        "\r\n",
        "args['task_name']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RTE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI0OpKgISsEj",
        "outputId": "6c4d107e-8dd1-4331-9410-7f20c9317d60"
      },
      "source": [
        "\r\n",
        "!ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collab.ipynb\t\t\t\t      README.md\n",
            "emily_run_glue_experiment.sh\t\t      repo_illustration.png\n",
            "finetuning_torchvision_models_tutorial.ipynb  requirements.txt\n",
            "glue_utils.py\t\t\t\t      run_glue_datasets.py\n",
            "__init__.py\t\t\t\t      run_glue_experiment.py\n",
            "LICENSE\t\t\t\t\t      run_glue.py\n",
            "manipulate_model.py\t\t\t      ryan_run_glue_experiment.sh\n",
            "mixout-fan-in.ipynb\t\t\t      ryan.sh\n",
            "mixout.ipynb\t\t\t\t      sample_commands\n",
            "mixout.py\t\t\t\t      summarize_results.py\n",
            "model_utils.py\t\t\t\t      train.py\n",
            "options.py\t\t\t\t      validate.py\n",
            "prior_wd_optim.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c13565e99d8469494a7ea679f0a772f",
            "88358b930a45426ea66d22c44b22810d",
            "e3e89bba2ce74511b7fdd8001e8bb3d7",
            "99040e9f32f9488cab5800d64a2b13f8",
            "f91674bc38c34e4b9eb628689310c607",
            "0a2612b2825a4b238cbd4115a6675fb2",
            "89eaea86a8da4700b37eae598cdfa44f",
            "d8963017b9374008882526b484ba26e1"
          ]
        },
        "id": "lwJdCUJXYVlL",
        "outputId": "67d78160-11fb-42cf-9285-06c7c81864e6"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "\r\n",
        "        all_datasets = ['rte','sts-b','mrpc','cola']\r\n",
        "        metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc']\r\n",
        "        metrics = dict(zip(all_datasets, metrics))\r\n",
        "        result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        results = run_glue_main(args)\r\n",
        "        \r\n",
        "        score = results[result_key]\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "DATASETS = [\"RTE\"]\r\n",
        "\r\n",
        "\r\n",
        "# for dataset in DATASETS:\r\n",
        "#     seeds = range(args.trials)\r\n",
        "#     args.task_name = dataset\r\n",
        "#     args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "#     experiment(seeds)\r\n",
        "def run_real(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    params.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < 20:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)\r\n",
        "lnum = [args.frozen_layers, args.mixout_layers, args.finetune_layers, args.mixout_layers]\r\n",
        "paramnames = f\"lay_{lnum[0]}_{lnum[1]}_{lnum[2]}_{lnum[3]}_reg_{args.l2_reg_mult}_regdecay_{args.l2_reg_decay}_\"\r\n",
        "run_real(paramnames, DATASETS, df = None, sheet = sheet, params = args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/01/2021 00:21:06 - WARNING - run_glue -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "01/01/2021 00:21:07 - INFO - filelock -   Lock 139654997802176 acquired on /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8.lock\n",
            "01/01/2021 00:21:07 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmphod0ogcr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c13565e99d8469494a7ea679f0a772f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/01/2021 00:21:07 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json in cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "01/01/2021 00:21:07 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "01/01/2021 00:21:07 - INFO - filelock -   Lock 139654997802176 released on /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8.lock\n",
            "01/01/2021 00:21:07 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "01/01/2021 00:21:07 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/01/2021 00:21:08 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "01/01/2021 00:21:08 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"rte\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "01/01/2021 00:21:08 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "01/01/2021 00:21:08 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "01/01/2021 00:21:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "01/01/2021 00:21:10 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "01/01/2021 00:21:44 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "01/01/2021 00:21:44 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "01/01/2021 00:21:55 - INFO - run_glue -   Training/evaluation parameters <__main__.dict2obj.<locals>.C object at 0x7f03e7860b70>\n",
            "01/01/2021 00:21:55 - INFO - run_glue -   Loading features from cached file /content/drive/My Drive/mixout/ModernML_TinyBert/glue_data/RTE/cached_train_bert-large-uncased_64_rte\n",
            "01/01/2021 00:21:55 - INFO - run_glue -   Loading features from cached file /content/drive/My Drive/mixout/ModernML_TinyBert/glue_data/RTE/cached_dev_bert-large-uncased_64_rte\n",
            "01/01/2021 00:21:56 - INFO - run_glue -   ***** Running training *****\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Num examples = 2490\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Num Epochs = 3\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Instantaneous batch size per GPU = 8\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Gradient Accumulation steps = 4\n",
            "01/01/2021 00:21:56 - INFO - run_glue -     Total optimization steps = 234\n",
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "iteration:   0%|          | 0/312 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " unfreezing mixout layers \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "iteration:   0%|          | 1/312 [00:03<17:17,  3.34s/it]\u001b[A\n",
            "iteration:   1%|          | 2/312 [00:06<16:31,  3.20s/it]\u001b[A\n",
            "iteration:   1%|          | 3/312 [00:09<16:04,  3.12s/it]\u001b[A\n",
            "iteration:   1%|▏         | 4/312 [00:12<15:51,  3.09s/it]\u001b[A\n",
            "iteration:   2%|▏         | 5/312 [00:15<15:34,  3.04s/it]\u001b[A\n",
            "iteration:   2%|▏         | 6/312 [00:18<15:33,  3.05s/it]\u001b[A\n",
            "iteration:   2%|▏         | 7/312 [00:21<15:20,  3.02s/it]\u001b[A\n",
            "iteration:   3%|▎         | 8/312 [00:24<15:22,  3.03s/it]\u001b[A\n",
            "iteration:   3%|▎         | 9/312 [00:27<15:13,  3.02s/it]\u001b[A\n",
            "iteration:   3%|▎         | 10/312 [00:30<15:02,  2.99s/it]\u001b[A\n",
            "iteration:   4%|▎         | 11/312 [00:32<14:46,  2.94s/it]\u001b[A\n",
            "iteration:   4%|▍         | 12/312 [00:35<14:48,  2.96s/it]\u001b[A\n",
            "iteration:   4%|▍         | 13/312 [00:38<14:52,  2.99s/it]\u001b[A\n",
            "iteration:   4%|▍         | 14/312 [00:41<14:37,  2.94s/it]\u001b[A\n",
            "iteration:   5%|▍         | 15/312 [00:44<14:40,  2.96s/it]\u001b[A\n",
            "iteration:   5%|▌         | 16/312 [00:47<14:53,  3.02s/it]\u001b[A\n",
            "iteration:   5%|▌         | 17/312 [00:50<14:31,  2.95s/it]\u001b[A\n",
            "iteration:   6%|▌         | 18/312 [00:53<14:24,  2.94s/it]\u001b[A\n",
            "iteration:   6%|▌         | 19/312 [00:56<14:11,  2.91s/it]\u001b[A\n",
            "iteration:   6%|▋         | 20/312 [00:59<14:14,  2.93s/it]\u001b[A\n",
            "iteration:   7%|▋         | 21/312 [01:02<14:00,  2.89s/it]\u001b[A\n",
            "iteration:   7%|▋         | 22/312 [01:05<13:57,  2.89s/it]\u001b[A\n",
            "iteration:   7%|▋         | 23/312 [01:08<13:54,  2.89s/it]\u001b[A\n",
            "iteration:   8%|▊         | 24/312 [01:11<14:00,  2.92s/it]\u001b[A\n",
            "iteration:   8%|▊         | 25/312 [01:13<13:59,  2.92s/it]\u001b[A\n",
            "iteration:   8%|▊         | 26/312 [01:16<14:02,  2.94s/it]\u001b[A\n",
            "iteration:   9%|▊         | 27/312 [01:20<14:06,  2.97s/it]\u001b[A\n",
            "iteration:   9%|▉         | 28/312 [01:23<14:15,  3.01s/it]\u001b[A\n",
            "iteration:   9%|▉         | 29/312 [01:25<14:00,  2.97s/it]\u001b[A\n",
            "iteration:  10%|▉         | 30/312 [01:28<13:50,  2.94s/it]\u001b[A\n",
            "iteration:  10%|▉         | 31/312 [01:31<13:36,  2.90s/it]\u001b[A\n",
            "iteration:  10%|█         | 32/312 [01:34<13:36,  2.91s/it]\u001b[A\n",
            "iteration:  11%|█         | 33/312 [01:37<13:29,  2.90s/it]\u001b[A\n",
            "iteration:  11%|█         | 34/312 [01:40<13:27,  2.90s/it]\u001b[A\n",
            "iteration:  11%|█         | 35/312 [01:43<13:43,  2.97s/it]\u001b[A\n",
            "iteration:  12%|█▏        | 36/312 [01:46<13:42,  2.98s/it]\u001b[A\n",
            "iteration:  12%|█▏        | 37/312 [01:49<13:30,  2.95s/it]\u001b[A\n",
            "iteration:  12%|█▏        | 38/312 [01:52<13:24,  2.93s/it]\u001b[A\n",
            "iteration:  12%|█▎        | 39/312 [01:55<13:16,  2.92s/it]\u001b[A\n",
            "iteration:  13%|█▎        | 40/312 [01:58<13:28,  2.97s/it]\u001b[A\n",
            "iteration:  13%|█▎        | 41/312 [02:01<13:17,  2.94s/it]\u001b[A\n",
            "iteration:  13%|█▎        | 42/312 [02:03<13:04,  2.91s/it]\u001b[A\n",
            "iteration:  14%|█▍        | 43/312 [02:06<12:58,  2.90s/it]\u001b[A\n",
            "iteration:  14%|█▍        | 44/312 [02:09<13:09,  2.95s/it]\u001b[A\n",
            "iteration:  14%|█▍        | 45/312 [02:12<13:03,  2.93s/it]\u001b[A\n",
            "iteration:  15%|█▍        | 46/312 [02:15<13:02,  2.94s/it]\u001b[A\n",
            "iteration:  15%|█▌        | 47/312 [02:18<12:52,  2.92s/it]\u001b[A\n",
            "iteration:  15%|█▌        | 48/312 [02:21<12:53,  2.93s/it]\u001b[A\n",
            "iteration:  16%|█▌        | 49/312 [02:24<12:45,  2.91s/it]\u001b[A\n",
            "iteration:  16%|█▌        | 50/312 [02:27<12:37,  2.89s/it]\u001b[A\n",
            "iteration:  16%|█▋        | 51/312 [02:30<12:33,  2.89s/it]\u001b[A\n",
            "iteration:  17%|█▋        | 52/312 [02:33<12:40,  2.92s/it]\u001b[A\n",
            "iteration:  17%|█▋        | 53/312 [02:36<12:45,  2.96s/it]\u001b[A\n",
            "iteration:  17%|█▋        | 54/312 [02:39<12:51,  2.99s/it]\u001b[A\n",
            "iteration:  18%|█▊        | 55/312 [02:42<12:54,  3.01s/it]\u001b[A\n",
            "iteration:  18%|█▊        | 56/312 [02:45<13:01,  3.05s/it]\u001b[A\n",
            "iteration:  18%|█▊        | 57/312 [02:48<12:51,  3.03s/it]\u001b[A\n",
            "iteration:  19%|█▊        | 58/312 [02:51<12:44,  3.01s/it]\u001b[A\n",
            "iteration:  19%|█▉        | 59/312 [02:54<12:26,  2.95s/it]\u001b[A\n",
            "iteration:  19%|█▉        | 60/312 [02:57<12:23,  2.95s/it]\u001b[A\n",
            "iteration:  20%|█▉        | 61/312 [03:00<12:22,  2.96s/it]\u001b[A\n",
            "iteration:  20%|█▉        | 62/312 [03:03<12:14,  2.94s/it]\u001b[A\n",
            "iteration:  20%|██        | 63/312 [03:06<12:15,  2.96s/it]\u001b[A\n",
            "iteration:  21%|██        | 64/312 [03:09<12:12,  2.95s/it]\u001b[A\n",
            "iteration:  21%|██        | 65/312 [03:12<12:12,  2.97s/it]\u001b[A\n",
            "iteration:  21%|██        | 66/312 [03:15<12:11,  2.98s/it]\u001b[A\n",
            "iteration:  21%|██▏       | 67/312 [03:17<12:01,  2.94s/it]\u001b[A\n",
            "iteration:  22%|██▏       | 68/312 [03:20<11:59,  2.95s/it]\u001b[A\n",
            "iteration:  22%|██▏       | 69/312 [03:23<11:52,  2.93s/it]\u001b[A\n",
            "iteration:  22%|██▏       | 70/312 [03:26<11:40,  2.89s/it]\u001b[A\n",
            "iteration:  23%|██▎       | 71/312 [03:29<11:37,  2.90s/it]\u001b[A\n",
            "iteration:  23%|██▎       | 72/312 [03:32<11:41,  2.92s/it]\u001b[A\n",
            "iteration:  23%|██▎       | 73/312 [03:35<11:47,  2.96s/it]\u001b[A\n",
            "iteration:  24%|██▎       | 74/312 [03:38<11:35,  2.92s/it]\u001b[A\n",
            "iteration:  24%|██▍       | 75/312 [03:41<11:29,  2.91s/it]\u001b[A\n",
            "iteration:  24%|██▍       | 76/312 [03:44<11:27,  2.91s/it]\u001b[A\n",
            "iteration:  25%|██▍       | 77/312 [03:47<11:25,  2.92s/it]\u001b[A\n",
            "iteration:  25%|██▌       | 78/312 [03:49<11:21,  2.91s/it]\u001b[A\n",
            "iteration:  25%|██▌       | 79/312 [03:52<11:17,  2.91s/it]\u001b[A\n",
            "iteration:  26%|██▌       | 80/312 [03:55<11:18,  2.93s/it]\u001b[A\n",
            "iteration:  26%|██▌       | 81/312 [03:58<11:11,  2.91s/it]\u001b[A\n",
            "iteration:  26%|██▋       | 82/312 [04:01<11:16,  2.94s/it]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIPBoN9hKac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a72af11-85b0-44f3-fa90-61459b4fb5dc"
      },
      "source": [
        "!ls '/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CoLA  diagnostic  MNLI\tMRPC  QNLI  QQP  RTE  SNLI  SST-2  STS-B  WNLI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSYTx4YohKQ9"
      },
      "source": [
        "3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Z2s4J9hJOM"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEbSEwVeo6U"
      },
      "source": [
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrX8V-MCe0ta"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2bC5tUjdSz-"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29dtysoIgzMl"
      },
      "source": [
        "\r\n",
        "args.data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZHyH8_GJBNS"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"CoLA\", \"STS-B\"]\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        run_glue_main(args)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # revisiting finetuned bert (https://arxiv.org/pdf/2006.05987.pdf) uses 20 random seeds\r\n",
        "    seeds = range(args.trials)\r\n",
        "    if not args.all_datasets:\r\n",
        "        args.data_dir = os.path.join(data_diar, args.task_name)\r\n",
        "        experiment(seeds)\r\n",
        "    else:\r\n",
        "        for dataset in DATASETS:\r\n",
        "            args.task_name = dataset\r\n",
        "            args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "            experiment(seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMmyARZeahpj"
      },
      "source": [
        "# !echo '''python run_glue_datasets.py \\\r\n",
        "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "#     --do_train --data_dir /content/ModernML_TinyBert/glue_data/RTE --max_seq_length 16 \\\r\n",
        "#     --per_gpu_eval_batch_size 64 --weight_decay 0 --seed 0 \\\r\n",
        "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 32 \\\r\n",
        "#     --gradient_accumulation_steps 1 --logging_steps 0 --num_loggings 10 \\\r\n",
        "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /content/ModernML_TinyBert/hf-transformers-cache \\\r\n",
        "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "#     --output_dir bert_output/REINIT5/RTE/SEED0 \\\r\n",
        "#     --reinit_pooler --reinit_layers 5''' > sample_commands/run.sh\r\n",
        "\r\n",
        "!echo '''python run_glue_datasets.py \\\r\n",
        "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "    --do_train --data_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\" --max_seq_length 64 \\\r\n",
        "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\r\n",
        "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\r\n",
        "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\r\n",
        "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" \\\r\n",
        "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "    --output_dir tests/FULLTESTS/classic --all_datasets \\\r\n",
        "    --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\r\n",
        "    --trials 10''' > sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjWX1NsPYg2"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLlHIloufYic"
      },
      "source": [
        "!sh sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nLTvP3azsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}