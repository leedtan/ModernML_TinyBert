{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySh1iYWIQMzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7768d7-e2f6-4f89-b003-db3711c6bb28"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "NUM_TRIALS = 20"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yc320aO8Yq5",
        "outputId": "c5bc85c0-f107-4eb8-98aa-a59ec1bf39ed"
      },
      "source": [
        "pip install gspread==3.6\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gspread==3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/ba/bc8de4f5077bd34bc873bdd67a89cb29c4f181abba8a836d2c6a0a142365/gspread-3.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (2.23.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (0.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (3.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (51.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread==3.6) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XimlS4I8e3_"
      },
      "source": [
        "import numpy as np\r\n",
        "import pdb\r\n",
        "import pandas as pd\r\n",
        "import numbers\r\n",
        "from google.colab import auth\r\n",
        "import os\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6MMqgDf2dX"
      },
      "source": [
        "%%writefile setup.sh\r\n",
        "\r\n",
        "git clone https://github.com/NVIDIA/apex\r\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjAPAUvOS_3"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAs8j21N9ie"
      },
      "source": [
        "# %cd drive/My Drive/mixout/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSihpO2UB3KB"
      },
      "source": [
        "!git clone https://github.com/leedtan/ModernML_TinyBert.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbXC3ftfCG5b"
      },
      "source": [
        "os.chdir('ModernML_TinyBert')\r\n",
        "# !python download_glue_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6v64IffA-m"
      },
      "source": [
        "os.chdir('revisit-bert-finetuning')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMpPx5qVbtxo"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U4ze4fDiwly"
      },
      "source": [
        "!git checkout some_frozen_mixout_reg_scaling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc9De3PNlEAI"
      },
      "source": [
        "!cat ryan.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TSNnAAAsyMS"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kea-k7zqs5"
      },
      "source": [
        "\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "def get_df(sheet):\r\n",
        "  df = pd.DataFrame(sheet.get_all_values())\r\n",
        "  df.columns = df.iloc[0,:]\r\n",
        "  df.index = df.iloc[:,0]\r\n",
        "  df = df.iloc[1:,1:]\r\n",
        "  return df\r\n",
        "  \r\n",
        "def get_row_num(df, sheet, paramnames):\r\n",
        "  if paramnames in df.index:\r\n",
        "    rowidx = df.index.to_list().index(paramnames) + 1\r\n",
        "  else:\r\n",
        "    current_max_row = len(sheet.get_all_values())\r\n",
        "    rowidx = int(current_max_row) + 1\r\n",
        "  return rowidx\r\n",
        "def check_run(paramnames, task, df = None, sheet = None):\r\n",
        "  if 1:# df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  if paramnames in df.index:\r\n",
        "    idx = df.columns.to_list().index(task)\r\n",
        "    row = df.loc[paramnames,:]\r\n",
        "    rowiloc = row.iloc[idx+1]\r\n",
        "    if rowiloc == '':\r\n",
        "      return True\r\n",
        "    if not isinstance(rowiloc, numbers.Number):\r\n",
        "      if isinstance(rowiloc, str) and rowiloc.isnumeric():\r\n",
        "        rowiloc = int(rowiloc)\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "    if rowiloc >= NUM_TRIALS:\r\n",
        "      return False\r\n",
        "  return True\r\n",
        "def run(paramnames, task, df, sheet, params = {}):\r\n",
        "  df = get_df(sheet)\r\n",
        "  if paramnames not in df.index:\r\n",
        "    row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "    sheet.update(f\"A{row_idx}\", [[paramnames]])\r\n",
        "    df = get_df(sheet)\r\n",
        "  row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "  df = get_df(sheet)\r\n",
        "  idx = df.columns.to_list().index(task)\r\n",
        "  count = df.iloc[row_idx-1, idx+1]\r\n",
        "  if count == '':\r\n",
        "    count = 0\r\n",
        "    avg = 0\r\n",
        "  avg = df.iloc[row_idx-1, idx]\r\n",
        "  if avg == '':\r\n",
        "    avg = 0\r\n",
        "  avg = float(avg)\r\n",
        "  count = int(count)\r\n",
        "  \r\n",
        "  all_datasets = ['rte','sts-b','mrpc','cola']\r\n",
        "  metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc']\r\n",
        "  metrics = dict(zip(all_datasets, metrics))\r\n",
        "  result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "  args.seed = seed = count + 1\r\n",
        "  args.output_dir = (\r\n",
        "      output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "  )\r\n",
        "  results = run_glue_main(args)\r\n",
        "  print(type(results))\r\n",
        "  print(results)\r\n",
        "  if 'acc' in results:\r\n",
        "    score = results['acc']\r\n",
        "  elif 'pearson' in results:\r\n",
        "    score = results['pearson']\r\n",
        "  print('avg',type(avg),avg,'count',type(count),count,'score',type(score),score,)\r\n",
        "  newavg = (avg * count + score) / (count + 1)\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 2)}{row_idx+1}\", [[count+1]])\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 1)}{row_idx+1}\", [[newavg]])\r\n",
        "\r\n",
        "  return True\r\n",
        "def simulate(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < NUM_TRIALS:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_Zpy55Reav"
      },
      "source": [
        "def dict2obj(d):\r\n",
        "    if isinstance(d, list):\r\n",
        "        d = [dict2obj(x) for x in d]\r\n",
        "    if not isinstance(d, dict):\r\n",
        "        return d\r\n",
        "    class C(object):\r\n",
        "        def __init__(self):\r\n",
        "          pass\r\n",
        "        def __call__(self):\r\n",
        "          pass\r\n",
        "        pass\r\n",
        "    o = C()\r\n",
        "    for k in d:\r\n",
        "        o.__dict__[k] = dict2obj(d[k])\r\n",
        "    return o\r\n",
        "dict2obj({'b':2}).b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz817xVTxL9"
      },
      "source": [
        "args ={'model_type': 'bert', 'model_name_or_path': 'bert-large-uncased', 'task_name': 'RTE', \r\n",
        "    'do_train':True, 'data_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\", 'max_seq_length': 64, \r\n",
        "    'per_gpu_eval_batch_size': 8, 'weight_decay': 0, 'seed': 1, \r\n",
        "    'overwrite_output_dir':True, 'do_lower_case':True, 'per_gpu_train_batch_size': 8, \r\n",
        "    'gradient_accumulation_steps': 4, 'logging_steps': 0, 'num_loggings': 10, \r\n",
        "    'save_steps': 0, 'test_val_split':True, 'use_torch_adamw':True, \r\n",
        "    'cache_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" ,\r\n",
        "    'num_train_epochs': 3.0, 'warmup_ratio': 0.1, 'learning_rate': 2e-05 ,\r\n",
        "    'output_dir': 'tests/FULLTESTS/classic', 'all_datasets':True, \r\n",
        "    'reinit_pooler': True, 'normalize': True, 'mixout_layers': 12, 'mixout': .3, \r\n",
        "    'trials': 10}\r\n",
        "\r\n",
        "for name, default_val in zip([\"data_dir\", \"model_type\", \"model_name_or_path\", \"task_name\", \"output_dir\",\r\n",
        " \"config_name\", \"tokenizer_name\", \"cache_dir\", \"max_seq_length\", \"do_train\",\"do_lower_case\", \"save_best\",\r\n",
        "  \"save_last\", \"train_batch_size\", \"per_gpu_train_batch_size\", \"per_gpu_eval_batch_size\", \"gradient_accumulation_steps\",\r\n",
        "   \"learning_rate\", \"layerwise_learning_rate_decay\", \"weight_decay\", \"adam_epsilon\", \"max_grad_norm\", \"num_train_epochs\", \r\n",
        "   \"max_steps\", \"warmup_steps\", \"warmup_ratio\", \"weight_logging_steps\", \"logging_steps\", \"num_loggings\", \"save_steps\", \r\n",
        "   \"no_cuda\",\"overwrite_output_dir\", \"overwrite_cache\", \"seed\", \"fp16\", \"fp16_opt_level\", \"local_rank\", \"server_ip\",\r\n",
        "   \"server_port\",\"use_bertadam\",\"use_torch_adamw\",\"downsample_trainset\", \"resplit_val\", \"reinit_layers\", \"mixout_layers\",\r\n",
        "    \"unfreeze_after_epoch\", \"reinit_pooler\",\"l2_scaling\",\"normalize\",\"all_datasets\",\"layer_mixout\",\"rezero_layers\", \"mixout\",\r\n",
        "     \"mixout_decay\", \"trials\", \"prior_weight_decay\", \"test_val_split\",'frozen_layers', 'finetune_layers',\r\n",
        "      'l2_reg_decay', 'l2_reg_mult'], \r\n",
        "      [None, None, None, None, None, '', '', '', 128, False, False, False, False, 0, 8, 8,\r\n",
        "1, 5e-5, 1.0, 0.0, 1e-8, 1.0, 3.0, -1, 0, 0, 10, 0, 0, 500, False, False, False, 42,\r\n",
        "False, '01', -1, '', '', False, False, -1, 0, 0, 0, 0, False, False, False, False, False, \r\n",
        "0, 0.0, 1.0, NUM_TRIALS, False, False, 0, 0, 1.0, 3e-3]):\r\n",
        "    if name not in args:\r\n",
        "        args[name] = default_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwaXBqycg8mG"
      },
      "source": [
        "\r\n",
        "args['task_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI0OpKgISsEj"
      },
      "source": [
        "\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJdCUJXYVlL"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "\r\n",
        "        all_datasets = ['rte','sts-b','mrpc','cola']\r\n",
        "        metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc']\r\n",
        "        metrics = dict(zip(all_datasets, metrics))\r\n",
        "        result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        results = run_glue_main(args)\r\n",
        "        \r\n",
        "        score = results[result_key]\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "# DATASETS = [\"RTE\"]\r\n",
        "\r\n",
        "\r\n",
        "# for dataset in DATASETS:\r\n",
        "#     seeds = range(args.trials)\r\n",
        "#     args.task_name = dataset\r\n",
        "#     args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "#     experiment(seeds)\r\n",
        "def run_real(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    args.task_name = task\r\n",
        "    # params.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < NUM_TRIALS:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)\r\n",
        "lnum = [args.frozen_layers, args.mixout_layers, args.finetune_layers, args.mixout_layers]\r\n",
        "paramnames = f\"lay_{lnum[0]}_{lnum[1]}_{lnum[2]}_{lnum[3]}_reg_{args.l2_reg_mult}_regdecay_{args.l2_reg_decay}_\"\r\n",
        "run_real(paramnames, DATASETS, df = None, sheet = sheet, params = args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIPBoN9hKac"
      },
      "source": [
        "!ls '/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSYTx4YohKQ9"
      },
      "source": [
        "3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEbSEwVeo6U"
      },
      "source": [
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrX8V-MCe0ta"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2bC5tUjdSz-"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29dtysoIgzMl"
      },
      "source": [
        "\r\n",
        "args.data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZHyH8_GJBNS"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"CoLA\", \"STS-B\"]\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        run_glue_main(args)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # revisiting finetuned bert (https://arxiv.org/pdf/2006.05987.pdf) uses 20 random seeds\r\n",
        "    seeds = range(args.trials)\r\n",
        "    if not args.all_datasets:\r\n",
        "        args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "        experiment(seeds)\r\n",
        "    else:\r\n",
        "        for dataset in DATASETS:\r\n",
        "            args.task_name = dataset\r\n",
        "            args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "            experiment(seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMmyARZeahpj"
      },
      "source": [
        "# !echo '''python run_glue_datasets.py \\\r\n",
        "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "#     --do_train --data_dir /content/ModernML_TinyBert/glue_data/RTE --max_seq_length 16 \\\r\n",
        "#     --per_gpu_eval_batch_size 64 --weight_decay 0 --seed 0 \\\r\n",
        "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 32 \\\r\n",
        "#     --gradient_accumulation_steps 1 --logging_steps 0 --num_loggings 10 \\\r\n",
        "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /content/ModernML_TinyBert/hf-transformers-cache \\\r\n",
        "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "#     --output_dir bert_output/REINIT5/RTE/SEED0 \\\r\n",
        "#     --reinit_pooler --reinit_layers 5''' > sample_commands/run.sh\r\n",
        "\r\n",
        "!echo '''python run_glue_datasets.py \\\r\n",
        "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "    --do_train --data_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\" --max_seq_length 64 \\\r\n",
        "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\r\n",
        "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\r\n",
        "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\r\n",
        "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" \\\r\n",
        "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "    --output_dir tests/FULLTESTS/classic --all_datasets \\\r\n",
        "    --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\r\n",
        "    --trials 10''' > sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjWX1NsPYg2"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLlHIloufYic"
      },
      "source": [
        "!sh sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nLTvP3azsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}