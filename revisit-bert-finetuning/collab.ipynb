{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebookversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySh1iYWIQMzN"
      },
      "source": [
        "# from google.colab import drive\r\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yc320aO8Yq5",
        "outputId": "cfee031c-7b1c-4cdd-e4bc-4418836ff3bc"
      },
      "source": [
        "pip install gspread==3.6\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread==3.6 in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (1.17.2)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread==3.6) (0.4.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (51.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread==3.6) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread==3.6) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.12.0->gspread==3.6) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XimlS4I8e3_"
      },
      "source": [
        "import numpy as np\r\n",
        "import pdb\r\n",
        "import pandas as pd\r\n",
        "import numbers\r\n",
        "from google.colab import auth\r\n",
        "import os\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXWzpoC96RZp"
      },
      "source": [
        "\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "def get_df(sheet):\r\n",
        "  df = pd.DataFrame(sheet.get_all_values())\r\n",
        "  df.columns = df.iloc[0,:]\r\n",
        "  df.index = df.iloc[:,0]\r\n",
        "  df = df.iloc[1:,1:]\r\n",
        "  return df\r\n",
        "  \r\n",
        "def get_row_num(df, sheet, paramnames):\r\n",
        "  if paramnames in df.index:\r\n",
        "    rowidx = df.index.to_list().index(paramnames) + 1\r\n",
        "  else:\r\n",
        "    current_max_row = len(sheet.get_all_values())\r\n",
        "    rowidx = int(current_max_row) + 1\r\n",
        "  return rowidx\r\n",
        "def check_run(paramnames, task, df = None, sheet = None):\r\n",
        "  if 1:# df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  if paramnames in df.index:\r\n",
        "    idx = df.columns.to_list().index(task)\r\n",
        "    row = df.loc[paramnames,:]\r\n",
        "    rowiloc = row.iloc[idx+1]\r\n",
        "    if rowiloc == '':\r\n",
        "      return True\r\n",
        "    if not isinstance(rowiloc, numbers.Number):\r\n",
        "      if isinstance(rowiloc, str) and rowiloc.isnumeric():\r\n",
        "        rowiloc = int(rowiloc)\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "    if rowiloc >= 20:\r\n",
        "      return False\r\n",
        "  return True\r\n",
        "def run(paramnames, task, df, sheet, params = {}):\r\n",
        "  df = get_df(sheet)\r\n",
        "  if paramnames not in df.index:\r\n",
        "    row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "    sheet.update(f\"A{row_idx}\", [[paramnames]])\r\n",
        "    df = get_df(sheet)\r\n",
        "  row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "  df = get_df(sheet)\r\n",
        "  idx = df.columns.to_list().index(task)\r\n",
        "  result = np.random.rand()\r\n",
        "  count = df.iloc[row_idx-1, idx+1]\r\n",
        "  if count == '':\r\n",
        "    count = 0\r\n",
        "    avg = 0\r\n",
        "  else:\r\n",
        "    avg = float(df.iloc[row_idx-1, idx])\r\n",
        "  count = int(count)\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 2)}{row_idx+1}\", [[count+1]])\r\n",
        "  newval = np.random.rand()\r\n",
        "  newavg = (avg * count + newval) / (count + 1)\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 1)}{row_idx+1}\", [[newavg]])\r\n",
        "\r\n",
        "  return True\r\n",
        "def simulate(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < 20:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-6MMqgDf2dX",
        "outputId": "d4f45fbd-fa13-402d-b7de-bc67ea334895"
      },
      "source": [
        "%%writefile setup.sh\r\n",
        "\r\n",
        "git clone https://github.com/NVIDIA/apex\r\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjAPAUvOS_3"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAs8j21N9ie"
      },
      "source": [
        "# %cd drive/My Drive/mixout/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSihpO2UB3KB",
        "outputId": "6f1e7532-73b6-42dc-9c1a-91ccffec694e"
      },
      "source": [
        "!git clone https://github.com/leedtan/ModernML_TinyBert.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ModernML_TinyBert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbXC3ftfCG5b",
        "outputId": "979fed90-82d1-4658-a8cc-e2b453713f9e"
      },
      "source": [
        "os.chdir('ModernML_TinyBert')\r\n",
        "!python download_glue_data.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n",
            "Processing MRPC...\n",
            "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
            "\tCompleted!\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "Downloading and extracting STS...\n",
            "\tCompleted!\n",
            "Downloading and extracting MNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting SNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting QNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting RTE...\n",
            "\tCompleted!\n",
            "Downloading and extracting WNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting diagnostic...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6v64IffA-m"
      },
      "source": [
        "os.chdir('revisit-bert-finetuning')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMpPx5qVbtxo",
        "outputId": "dfee1b64-9537-43ce-f4ef-a7f071b86907"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.19.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.94)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.16.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.19.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.43->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4ze4fDiwly",
        "outputId": "7aa1cc4f-5d32-4dba-9796-fe00bcb63d4b"
      },
      "source": [
        "!git checkout some_frozen_mixout_reg_scaling"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already on 'some_frozen_mixout_reg_scaling'\n",
            "Your branch is up to date with 'origin/some_frozen_mixout_reg_scaling'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc9De3PNlEAI",
        "outputId": "1a18bbe3-17ef-443a-a89d-584d67bf48ff"
      },
      "source": [
        "!cat ryan.sh"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "    --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "    --output_dir tests/FULLTESTS/decay_50_to_20 \\\n",
            "    --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "    --trials 20 --mixout_decay 0.5\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/decay_90_to_20 \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .2 \\\n",
            "#     --trials 20 --mixout_decay 0.9\n",
            "\n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10\n",
            "    \n",
            "# ../../revisit-bert-finetuning/bert/bin/python run_glue_datasets.py \\\n",
            "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\n",
            "#     --do_train --data_dir ../../revisit-bert-finetuning/glue_data --max_seq_length 64 \\\n",
            "#     --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\n",
            "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\n",
            "#     --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\n",
            "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /home/ubuntu/hf-transformers-cache \\\n",
            "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\n",
            "#     --output_dir tests/FULLTESTS/classic --all_datasets \\\n",
            "#     --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\n",
            "#     --trials 10"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSNnAAAsyMS",
        "outputId": "b0048f26-7d9e-45f5-a4cf-d26ad73ca84d"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ_Zpy55Reav",
        "outputId": "6cbb6773-2ed7-4d0c-ecce-c6e0999ca2b0"
      },
      "source": [
        "def dict2obj(d):\r\n",
        "        if isinstance(d, list):\r\n",
        "            d = [dict2obj(x) for x in d]\r\n",
        "        if not isinstance(d, dict):\r\n",
        "            return d\r\n",
        "        class C(object):\r\n",
        "            pass\r\n",
        "        o = C()\r\n",
        "        for k in d:\r\n",
        "            o.__dict__[k] = dict2obj(d[k])\r\n",
        "        return o\r\n",
        "dict2obj({'b':2}).b"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz817xVTxL9"
      },
      "source": [
        "args ={'model_type': 'bert', 'model_name_or_path': 'bert-large-uncased', 'task_name': 'RTE', \r\n",
        "    'do_train':True, 'data_dir': \"/content/ModernML_TinyBert/glue_data\", 'max_seq_length': 64, \r\n",
        "    'per_gpu_eval_batch_size': 8, 'weight_decay': 0, 'seed': 1, \r\n",
        "    'overwrite_output_dir':True, 'do_lower_case':True, 'per_gpu_train_batch_size': 4, \r\n",
        "    'gradient_accumulation_steps': 8, 'logging_steps': 0, 'num_loggings': 10, \r\n",
        "    'save_steps': 0, 'test_val_split':True, 'use_torch_adamw':True, \r\n",
        "    'cache_dir': \"/content/ModernML_TinyBert/hf-transformers-cache\" ,\r\n",
        "    'num_train_epochs': 3.0, 'warmup_ratio': 0.1, 'learning_rate': 2e-05 ,\r\n",
        "    'output_dir': 'tests/FULLTESTS/classic', 'all_datasets':True, \r\n",
        "    'reinit_pooler': True, 'normalize': True, 'mixout_layers': 12, 'mixout': .3, \r\n",
        "    'trials': 10}\r\n",
        "\r\n",
        "for name, default_val in zip([\"data_dir\", \"model_type\", \"model_name_or_path\", \"task_name\", \"output_dir\",\r\n",
        " \"config_name\", \"tokenizer_name\", \"cache_dir\", \"max_seq_length\", \"do_train\",\"do_lower_case\", \"save_best\",\r\n",
        "  \"save_last\", \"train_batch_size\", \"per_gpu_train_batch_size\", \"per_gpu_eval_batch_size\", \"gradient_accumulation_steps\",\r\n",
        "   \"learning_rate\", \"layerwise_learning_rate_decay\", \"weight_decay\", \"adam_epsilon\", \"max_grad_norm\", \"num_train_epochs\", \r\n",
        "   \"max_steps\", \"warmup_steps\", \"warmup_ratio\", \"weight_logging_steps\", \"logging_steps\", \"num_loggings\", \"save_steps\", \r\n",
        "   \"no_cuda\",\"overwrite_output_dir\", \"overwrite_cache\", \"seed\", \"fp16\", \"fp16_opt_level\", \"local_rank\", \"server_ip\",\r\n",
        "   \"server_port\",\"use_bertadam\",\"use_torch_adamw\",\"downsample_trainset\", \"resplit_val\", \"reinit_layers\", \"mixout_layers\",\r\n",
        "    \"unfreeze_after_epoch\", \"reinit_pooler\",\"l2_scaling\",\"normalize\",\"all_datasets\",\"layer_mixout\",\"rezero_layers\", \"mixout\",\r\n",
        "     \"mixout_decay\", \"trials\", \"prior_weight_decay\", \"test_val_split\",'frozen_layers', 'finetune_layers',\r\n",
        "      'l2_reg_decay', 'l2_reg_mult'], \r\n",
        "      [None, None, None, None, None, '', '', '', 128, False, False, False, False, 0, 8, 8,\r\n",
        "1, 5e-5, 1.0, 0.0, 1e-8, 1.0, 3.0, -1, 0, 0, 10, 0, 0, 500, False, False, False, 42,\r\n",
        "False, '01', -1, '', '', False, False, -1, 0, 0, 0, 0, False, False, False, False, False, \r\n",
        "0, 0.0, 1.0, 20, False, False, 0, 0, 1.0, 3e-3]):\r\n",
        "    if name not in args:\r\n",
        "        args[name] = default_val"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwJdCUJXYVlL",
        "outputId": "8de36f34-f826-4473-b94e-7851e3a9f173"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        run_glue_main(args)\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "DATASETS = [\"RTE\"]\r\n",
        "\r\n",
        "\r\n",
        "for dataset in DATASETS:\r\n",
        "    seeds = range(args.trials)\r\n",
        "    args.task_name = dataset\r\n",
        "    args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    experiment(seeds)\r\n",
        "def run_real(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < 20:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)\r\n",
        "lnum = [args.frozen_layers, args.mixout_layers, args.finetune_layers, args.mixout_layers]\r\n",
        "paramnames = f\"lay_{lnum[0]}_{lnum[1]}_{lnum[2]}_{lnum[3]}_reg_{args.l2_reg_mult}_regdecay_{args.l2_reg_decay}_\"\r\n",
        "run_real()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/27/2020 04:40:36 - WARNING - run_glue -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/27/2020 04:40:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/27/2020 04:40:36 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/27/2020 04:40:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/27/2020 04:40:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"rte\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/27/2020 04:40:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /content/ModernML_TinyBert/hf-transformers-cache/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "12/27/2020 04:40:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/27/2020 04:40:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /content/ModernML_TinyBert/hf-transformers-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/27/2020 04:40:38 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /content/ModernML_TinyBert/hf-transformers-cache/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "12/27/2020 04:40:50 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "12/27/2020 04:40:50 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEbSEwVeo6U"
      },
      "source": [
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrX8V-MCe0ta"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2bC5tUjdSz-"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZHyH8_GJBNS"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"CoLA\", \"STS-B\"]\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "\r\n",
        "\r\n",
        "def experiment(seeds):\r\n",
        "    for seed in seeds:\r\n",
        "        args.seed = seed\r\n",
        "        args.output_dir = (\r\n",
        "            output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "        )\r\n",
        "        run_glue_main(args)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # revisiting finetuned bert (https://arxiv.org/pdf/2006.05987.pdf) uses 20 random seeds\r\n",
        "    seeds = range(args.trials)\r\n",
        "    if not args.all_datasets:\r\n",
        "        args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "        experiment(seeds)\r\n",
        "    else:\r\n",
        "        for dataset in DATASETS:\r\n",
        "            args.task_name = dataset\r\n",
        "            args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "            experiment(seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMmyARZeahpj"
      },
      "source": [
        "# !echo '''python run_glue_datasets.py \\\r\n",
        "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "#     --do_train --data_dir /content/ModernML_TinyBert/glue_data/RTE --max_seq_length 16 \\\r\n",
        "#     --per_gpu_eval_batch_size 64 --weight_decay 0 --seed 0 \\\r\n",
        "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 32 \\\r\n",
        "#     --gradient_accumulation_steps 1 --logging_steps 0 --num_loggings 10 \\\r\n",
        "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /content/ModernML_TinyBert/hf-transformers-cache \\\r\n",
        "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "#     --output_dir bert_output/REINIT5/RTE/SEED0 \\\r\n",
        "#     --reinit_pooler --reinit_layers 5''' > sample_commands/run.sh\r\n",
        "\r\n",
        "!echo '''python run_glue_datasets.py \\\r\n",
        "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "    --do_train --data_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\" --max_seq_length 64 \\\r\n",
        "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\r\n",
        "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\r\n",
        "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\r\n",
        "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" \\\r\n",
        "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "    --output_dir tests/FULLTESTS/classic --all_datasets \\\r\n",
        "    --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\r\n",
        "    --trials 10''' > sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjWX1NsPYg2"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLlHIloufYic"
      },
      "source": [
        "!sh sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nLTvP3azsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}