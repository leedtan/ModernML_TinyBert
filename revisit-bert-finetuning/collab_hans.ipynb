{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "collab_hans.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySh1iYWIQMzN",
        "outputId": "0628698a-9432-4058-f764-67b818768611"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "NUM_TRIALS = 20"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yc320aO8Yq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cde5dd-0384-417f-f774-7ee59b796e89"
      },
      "source": [
        "pip install gspread==3.6\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gspread==3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/ba/bc8de4f5077bd34bc873bdd67a89cb29c4f181abba8a836d2c6a0a142365/gspread-3.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from gspread==3.6) (0.4.3)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gspread==3.6) (1.27.1)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from gspread==3.6) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread==3.6) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread==3.6) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread==3.6) (4.2.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread==3.6) (54.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread==3.6) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread==3.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread==3.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.2.1->gspread==3.6) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread==3.6) (0.4.8)\n",
            "Installing collected packages: gspread\n",
            "  Found existing installation: gspread 3.0.1\n",
            "    Uninstalling gspread-3.0.1:\n",
            "      Successfully uninstalled gspread-3.0.1\n",
            "Successfully installed gspread-3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XimlS4I8e3_"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "import pdb\r\n",
        "import pandas as pd\r\n",
        "import numbers\r\n",
        "from google.colab import auth\r\n",
        "import os\r\n",
        "# auth.authenticate_user()\r\n",
        "\r\n",
        "import gspread \r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "my_json = '{\"access_token\": null, \"client_id\": \"32555940559.apps.googleusercontent.com\", \"client_secret\": \"ZmssLNjJy2998hD4CTg2ejr2\", \"refresh_token\": \"1//05jJdSPJetzqsCgYIARAAGAUSNwF-L9IrC9Z2KZtw_HEeZhH2aTBd8tpq3xmUCSbK_4ZBvRXMzpeQh7R28VjLV3laqoigF0qA4Rc\", \"token_expiry\": null, \"token_uri\": \"https://oauth2.googleapis.com/token\", \"user_agent\": \"Python client library\", \"revoke_uri\": \"https://oauth2.googleapis.com/revoke\", \"id_token\": null, \"id_token_jwt\": null, \"token_response\": null, \"scopes\": [], \"token_info_uri\": null, \"invalid\": false, \"_class\": \"GoogleCredentials\", \"_module\": \"oauth2client.client\"}'\r\n",
        "\r\n",
        "gc = gspread.authorize(GoogleCredentials.from_json(my_json))\r\n",
        "# gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1F8A5n3WVr9WXHDXZhv2w0BPaMC8uymUyxEWdI9UX6xg/edit#gid=0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6MMqgDf2dX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8f026a-1923-4f2d-9b45-0d94194b5079"
      },
      "source": [
        "%%writefile setup.sh\r\n",
        "\r\n",
        "git clone https://github.com/NVIDIA/apex\r\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjAPAUvOS_3"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAs8j21N9ie"
      },
      "source": [
        "# %cd drive/My Drive/mixout/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSihpO2UB3KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d70291-c66f-46ad-fa9c-c8cf1bb47b1f"
      },
      "source": [
        "!git clone https://github.com/leedtan/ModernML_TinyBert.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ModernML_TinyBert'...\n",
            "remote: Enumerating objects: 390, done.\u001b[K\n",
            "remote: Counting objects: 100% (390/390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 811 (delta 287), reused 290 (delta 193), pack-reused 421\u001b[K\n",
            "Receiving objects: 100% (811/811), 23.27 MiB | 31.36 MiB/s, done.\n",
            "Resolving deltas: 100% (519/519), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbXC3ftfCG5b"
      },
      "source": [
        "os.chdir('ModernML_TinyBert')\r\n",
        "# !python download_glue_data.py"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6v64IffA-m"
      },
      "source": [
        "os.chdir('revisit-bert-finetuning')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMpPx5qVbtxo"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U4ze4fDiwly"
      },
      "source": [
        "# works:\r\n",
        "# !git checkout 7589fbb94924c50ae9a47094729c16803a280d64\r\n",
        "# !git checkout 6a8da1135ae21c6bdd3d1d983b8aea90736736eb\r\n",
        "# !git checkout d3c118f11cf4035feca957eff7b34b4413f3c5d6\r\n",
        "!git checkout hans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc9De3PNlEAI"
      },
      "source": [
        "!cat ryan.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TSNnAAAsyMS"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibjxhDC0eARA"
      },
      "source": [
        "!python train_to_sheet.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kea-k7zqs5"
      },
      "source": [
        "\r\n",
        "sheet = wb.worksheet('results')\r\n",
        "def get_df(sheet):\r\n",
        "  df = pd.DataFrame(sheet.get_all_values())\r\n",
        "  df.columns = df.iloc[0,:]\r\n",
        "  df.index = df.iloc[:,0]\r\n",
        "  df = df.iloc[1:,1:]\r\n",
        "  return df\r\n",
        "  \r\n",
        "def get_row_num(df, sheet, paramnames):\r\n",
        "  if paramnames in df.index:\r\n",
        "    rowidx = df.index.to_list().index(paramnames) + 1\r\n",
        "  else:\r\n",
        "    current_max_row = len(sheet.get_all_values())\r\n",
        "    rowidx = int(current_max_row) + 1\r\n",
        "  return rowidx\r\n",
        "def check_run(paramnames, task, df = None, sheet = None):\r\n",
        "  if 1:# df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  if paramnames in df.index:\r\n",
        "    idx = df.columns.to_list().index(task)\r\n",
        "    row = df.loc[paramnames,:]\r\n",
        "    rowiloc = row.iloc[idx+1]\r\n",
        "    if rowiloc == '':\r\n",
        "      return True\r\n",
        "    if not isinstance(rowiloc, numbers.Number):\r\n",
        "      if isinstance(rowiloc, str) and rowiloc.isnumeric():\r\n",
        "        rowiloc = int(rowiloc)\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "    if rowiloc >= NUM_TRIALS:\r\n",
        "      return False\r\n",
        "  return True\r\n",
        "def run(paramnames, task, df, sheet, params = {}):\r\n",
        "  df = get_df(sheet)\r\n",
        "  if paramnames not in df.index:\r\n",
        "    row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "    sheet.update(f\"A{row_idx}\", [[paramnames]])\r\n",
        "    df = get_df(sheet)\r\n",
        "  row_idx = get_row_num(df, sheet, paramnames)\r\n",
        "  df = get_df(sheet)\r\n",
        "  idx = df.columns.to_list().index(task)\r\n",
        "  count = df.iloc[row_idx-1, idx+1]\r\n",
        "  if count == '':\r\n",
        "    count = 0\r\n",
        "    avg = 0\r\n",
        "  avg = df.iloc[row_idx-1, idx]\r\n",
        "  if avg == '':\r\n",
        "    avg = 0\r\n",
        "  avg = float(avg)\r\n",
        "  count = int(count)\r\n",
        "  \r\n",
        "  all_datasets = ['rte','sts-b','mrpc','cola', 'hans']\r\n",
        "  metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc', 'acc']\r\n",
        "  metrics = dict(zip(all_datasets, metrics))\r\n",
        "  result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "  args.seed = seed = count + 1\r\n",
        "  args.output_dir = (\r\n",
        "      output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "  )\r\n",
        "  try:\r\n",
        "    wb.add_worksheet(paramnames, 100, 10)\r\n",
        "  except:\r\n",
        "    pass\r\n",
        "  sheet2 = wb.worksheet(paramnames)\r\n",
        "  # df2 = get_df(sheet2)\r\n",
        "  df2 = pd.DataFrame(sheet2.get_all_values())\r\n",
        "  taskcolidx = all_datasets.index(args.task_name.lower())\r\n",
        "  row_idx2 = df2.shape[0]\r\n",
        "\r\n",
        "\r\n",
        "  results = run_glue_main(args)\r\n",
        "  print('RESULTS::::')\r\n",
        "  print(type(results))\r\n",
        "  print(results)\r\n",
        "  if args.task_name.lower() == 'mrpc':\r\n",
        "    score = results['f1']\r\n",
        "  elif 'acc' in results:\r\n",
        "    score = results['acc']\r\n",
        "  elif 'pearson' in results:\r\n",
        "    score = results['pearson']\r\n",
        "  print('avg',type(avg),avg,'count',type(count),count,'score',type(score),score,)\r\n",
        "  newavg = (avg * count + score) / (count + 1)\r\n",
        "\r\n",
        "  sheet2.update(f\"{chr(ord('a') + taskcolidx + 1)}{row_idx2+1}\", [[score]])\r\n",
        "\r\n",
        "\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 2)}{row_idx+1}\", [[count+1]])\r\n",
        "  sheet.update(f\"{chr(ord('a') + idx + 1)}{row_idx+1}\", [[newavg]])\r\n",
        "\r\n",
        "  return True\r\n",
        "def simulate(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < NUM_TRIALS:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_Zpy55Reav"
      },
      "source": [
        "def dict2obj(d):\r\n",
        "    if isinstance(d, list):\r\n",
        "        d = [dict2obj(x) for x in d]\r\n",
        "    if not isinstance(d, dict):\r\n",
        "        return d\r\n",
        "    class C(object):\r\n",
        "        def __init__(self):\r\n",
        "          pass\r\n",
        "        def __call__(self):\r\n",
        "          pass\r\n",
        "        pass\r\n",
        "    o = C()\r\n",
        "    for k in d:\r\n",
        "        o.__dict__[k] = dict2obj(d[k])\r\n",
        "    return o\r\n",
        "dict2obj({'b':2}).b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5RoqeUmUvYw"
      },
      "source": [
        "# args ={'model_type': 'bert', 'model_name_or_path': 'bert-large-uncased', 'task_name': 'RTE', \r\n",
        "#     'do_train':True, 'data_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\", 'max_seq_length': 64, \r\n",
        "#     'per_gpu_eval_batch_size': 8, 'weight_decay': 0, 'seed': 1, \r\n",
        "#     'overwrite_output_dir':True, 'do_lower_case':True, 'per_gpu_train_batch_size': 8, \r\n",
        "#     'gradient_accumulation_steps': 4, 'logging_steps': 0, 'num_loggings': 10, \r\n",
        "#     'save_steps': 0, 'test_val_split':True, 'use_torch_adamw':True, \r\n",
        "#     'cache_dir': \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" ,\r\n",
        "#     'num_train_epochs': 3.0, 'warmup_ratio': 0.1, 'learning_rate': 2e-05 ,\r\n",
        "#     'output_dir': 'tests/FULLTESTS/classic', 'all_datasets':True, \r\n",
        "#     'reinit_pooler': True, 'normalize': True, 'mixout_layers': 6, 'reinit_layers':6, 'mixout': .3, \r\n",
        "#     'trials': 10, 'l2_scaling':0}\r\n",
        "\r\n",
        "# args['mixout_layers'] = 9\r\n",
        "# args['reinit_layers'] = 3\r\n",
        "# # args['frozen_layers'] = 4\r\n",
        "# args['finetune_layers'] = 0\r\n",
        "# # args['l2_reg_decay'] = 1e-1\r\n",
        "# args['l2_reg_mult'] = 1e-2\r\n",
        "# args['reinit_pooler'] = True\r\n",
        "# if 0:\r\n",
        "#   args['reinit_pooler'] = False\r\n",
        "#   args['newmixout'] = 1\r\n",
        "# if 0:\r\n",
        "#   args['newmixout'] = 0\r\n",
        "#   args['gradient_accumulation_steps'] = 1\r\n",
        "#   args['per_gpu_train_batch_size'] = 32\r\n",
        "#   args['per_gpu_eval_batch_size'] = 32\r\n",
        "#   args['reinit_pooler'] = True\r\n",
        "#   # args['no_cuda'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz817xVTxL9"
      },
      "source": [
        "args = {\"model_type\" : \"bert\",\"model_name_or_path\" : \"bert-base-uncased\", \"task_name\" : \"hans\",\r\n",
        "    \"do_train\" : True, \"data_dir\" : \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\",\"max_seq_length\" : \"128\",\r\n",
        "    \"per_gpu_eval_batch_size\" : 32,\"weight_decay\" : 0,\"seed\" : 0,\r\n",
        "    \"overwrite_output_dir\" : True, \"do_lower_case\" : True, \"per_gpu_train_batch_size\" : 32,\r\n",
        "    \"gradient_accumulation_steps\" : 1,\"logging_steps\" : 0,\"num_loggings\" : 10,\r\n",
        "    \"save_steps\" : 0,\"test_val_split\" : False, \"use_torch_adamw\" : True, \"cache_dir\" : \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\", \r\n",
        "    \"num_train_epochs\" : 1.0,\"warmup_ratio\" : 0.1,\"learning_rate\" : 2e-05 ,\r\n",
        "    \"output_dir\" : \"tests/FULLTESTS/classic\",\"mixout\" : 0.1,\"no_cuda\": False , \"all_datasets\" : True\r\n",
        "}\r\n",
        "\r\n",
        "for name, default_val in zip([\"data_dir\", \"model_type\", \"model_name_or_path\", \"task_name\", \"output_dir\",\r\n",
        " \"config_name\", \"tokenizer_name\", \"cache_dir\", \"max_seq_length\", \"do_train\",\"do_lower_case\", \"save_best\",\r\n",
        "  \"save_last\", \"train_batch_size\", \"per_gpu_train_batch_size\", \"per_gpu_eval_batch_size\", \"gradient_accumulation_steps\",\r\n",
        "   \"learning_rate\", \"layerwise_learning_rate_decay\", \"weight_decay\", \"adam_epsilon\", \"max_grad_norm\", \"num_train_epochs\", \r\n",
        "   \"max_steps\", \"warmup_steps\", \"warmup_ratio\", \"weight_logging_steps\", \"logging_steps\", \"num_loggings\", \"save_steps\", \r\n",
        "   \"no_cuda\",\"overwrite_output_dir\", \"overwrite_cache\", \"seed\", \"fp16\", \"fp16_opt_level\", \"local_rank\", \"server_ip\",\r\n",
        "   \"server_port\",\"use_bertadam\",\"use_torch_adamw\",\"downsample_trainset\", \"resplit_val\", \"reinit_layers\", \"mixout_layers\",\r\n",
        "    \"unfreeze_after_epoch\", \"reinit_pooler\",\"l2_scaling\",\"normalize\",\"all_datasets\",\"layer_mixout\",\"rezero_layers\", \"mixout\",\r\n",
        "     \"mixout_decay\", \"trials\", \"prior_weight_decay\", \"test_val_split\",'frozen_layers', 'finetune_layers',\r\n",
        "      'l2_reg_decay', 'l2_reg_mult', 'newmixout'], \r\n",
        "      [None, None, None, None, None, '', '', '', 128, False, False, False, False, 0, 8, 8,\r\n",
        "1, 5e-5, 1.0, 0.0, 1e-8, 1.0, 3.0, -1, 0, 0, 10, 0, 0, 500, False, False, False, 42,\r\n",
        "False, '01', -1, '', '', False, False, -1, 0, 0, 0, 0, False, False, False, False, False, \r\n",
        "0, 0.0, 1.0, NUM_TRIALS, False, False, 0, 0, 1.0, 3e-3, 1]):\r\n",
        "    if name not in args:\r\n",
        "        args[name] = default_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwaXBqycg8mG"
      },
      "source": [
        "\r\n",
        "args['task_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRt0cTd4glOC"
      },
      "source": [
        "# !cat /content/ModernML_TinyBert/revisit-bert-finetuning/run_glue.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERqiM_IMbgvC"
      },
      "source": [
        "\r\n",
        "pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJdCUJXYVlL"
      },
      "source": [
        "from run_glue import main as run_glue_main\r\n",
        "from options import get_parser\r\n",
        "import os\r\n",
        "\r\n",
        "args =dict2obj(args)\r\n",
        "output_dir = args.output_dir\r\n",
        "data_dir = args.data_dir\r\n",
        "\r\n",
        "# def experiment(seeds):\r\n",
        "#     for seed in seeds:\r\n",
        "\r\n",
        "#         all_datasets = ['rte','sts-b','mrpc','cola', 'hans']\r\n",
        "#         metrics = ['test_acc', 'test_pearson', 'test_acc', 'test_mcc', 'acc']\r\n",
        "#         metrics = dict(zip(all_datasets, metrics))\r\n",
        "#         result_key = metrics[args.task_name.lower()]\r\n",
        "\r\n",
        "#         args.seed = seed\r\n",
        "#         args.output_dir = (\r\n",
        "#             output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "#         )\r\n",
        "#         results = run_glue_main(args)\r\n",
        "#         import pdb\r\n",
        "#         pdb.set_trace()\r\n",
        "#         score = results[result_key]\r\n",
        "\r\n",
        "DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "# DATASETS = [\"RTE\"]\r\n",
        "DATASETS = ['hans']\r\n",
        "\r\n",
        "\r\n",
        "# for dataset in DATASETS:\r\n",
        "#     seeds = range(args.trials)\r\n",
        "#     args.task_name = dataset\r\n",
        "#     args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "#     experiment(seeds)\r\n",
        "def run_real(paramnames, tasks, df = None, sheet = None, params = {}):\r\n",
        "  if df is None:\r\n",
        "    df = get_df(sheet)\r\n",
        "  for task in tasks:\r\n",
        "    args.task_name = task\r\n",
        "    # params.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "    i = 0\r\n",
        "    while check_run(paramnames, task, df, sheet) and i < NUM_TRIALS:\r\n",
        "      i += 1\r\n",
        "      run(paramnames, task, df, sheet, params = params)\r\n",
        "      df = get_df(sheet)\r\n",
        "lnum = [args.frozen_layers, args.mixout_layers, args.finetune_layers, args.reinit_layers]\r\n",
        "paramnames = f\"l_{lnum[0]}_{lnum[1]}_{lnum[2]}_{lnum[3]}_reg_{args.l2_reg_mult}_regdecay_{args.l2_reg_decay}_ep_{args.num_train_epochs}_decay_{args.l2_reg_decay}\"\r\n",
        "mix = {0:'cho',1:'ours'}[args.newmixout]\r\n",
        "paramnames = f\"hans\"\r\n",
        "# paramnames = f\"old_nogradacc_{lnum[0]}_{lnum[1]}_{lnum[2]}_{lnum[3]}\"\r\n",
        "# pdb.run('''run_real(paramnames, DATASETS, df = None, sheet = sheet, params = args)''')\r\n",
        "run_real(paramnames, DATASETS, df = None, sheet = sheet, params = args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIPBoN9hKac"
      },
      "source": [
        "!ls '/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzjA5WwvQ8uw"
      },
      "source": [
        "eval_datasets[0].tensors[0] == train_dataloader.dataset.tensors[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-fR9YXxQ50M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEbSEwVeo6U"
      },
      "source": [
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrX8V-MCe0ta"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29dtysoIgzMl"
      },
      "source": [
        "\r\n",
        "args.data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZHyH8_GJBNS"
      },
      "source": [
        "# from run_glue import main as run_glue_main\r\n",
        "# from options import get_parser\r\n",
        "# import os\r\n",
        "\r\n",
        "# args =dict2obj(args)\r\n",
        "# output_dir = args.output_dir\r\n",
        "# data_dir = args.data_dir\r\n",
        "\r\n",
        "\r\n",
        "# DATASETS = [\"RTE\", \"MRPC\", \"CoLA\", \"STS-B\"]\r\n",
        "# DATASETS = [\"RTE\", \"MRPC\", \"STS-B\"]\r\n",
        "\r\n",
        "\r\n",
        "# def experiment(seeds):\r\n",
        "#     for seed in seeds:\r\n",
        "#         args.seed = seed\r\n",
        "#         args.output_dir = (\r\n",
        "#             output_dir + \"_DATASET_\" + args.task_name.lower() + \"_SEED_\" + str(seed)\r\n",
        "#         )\r\n",
        "#         run_glue_main(args)\r\n",
        "\r\n",
        "\r\n",
        "# if __name__ == \"__main__\":\r\n",
        "#     # revisiting finetuned bert (https://arxiv.org/pdf/2006.05987.pdf) uses 20 random seeds\r\n",
        "#     seeds = range(args.trials)\r\n",
        "#     if not args.all_datasets:\r\n",
        "#         args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "#         experiment(seeds)\r\n",
        "#     else:\r\n",
        "#         for dataset in DATASETS:\r\n",
        "#             args.task_name = dataset\r\n",
        "#             args.data_dir = os.path.join(data_dir, args.task_name)\r\n",
        "#             experiment(seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMmyARZeahpj"
      },
      "source": [
        "# !echo '''python run_glue_datasets.py \\\r\n",
        "#     --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "#     --do_train --data_dir /content/ModernML_TinyBert/glue_data/RTE --max_seq_length 16 \\\r\n",
        "#     --per_gpu_eval_batch_size 64 --weight_decay 0 --seed 0 \\\r\n",
        "#     --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 32 \\\r\n",
        "#     --gradient_accumulation_steps 1 --logging_steps 0 --num_loggings 10 \\\r\n",
        "#     --save_steps 0 --test_val_split --use_torch_adamw --cache_dir /content/ModernML_TinyBert/hf-transformers-cache \\\r\n",
        "#     --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "#     --output_dir bert_output/REINIT5/RTE/SEED0 \\\r\n",
        "#     --reinit_pooler --reinit_layers 5''' > sample_commands/run.sh\r\n",
        "\r\n",
        "!echo '''python run_glue_datasets.py \\\r\n",
        "    --model_type bert --model_name_or_path bert-large-uncased --task_name RTE \\\r\n",
        "    --do_train --data_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/glue_data\" --max_seq_length 64 \\\r\n",
        "    --per_gpu_eval_batch_size 8 --weight_decay 0 --seed 1 \\\r\n",
        "    --overwrite_output_dir --do_lower_case --per_gpu_train_batch_size 8 \\\r\n",
        "    --gradient_accumulation_steps 4 --logging_steps 0 --num_loggings 10 \\\r\n",
        "    --save_steps 0 --test_val_split --use_torch_adamw --cache_dir \"/content/drive/My Drive/mixout/ModernML_TinyBert/hf-transformers-cache\" \\\r\n",
        "    --num_train_epochs 3.0 --warmup_ratio 0.1 --learning_rate 2e-05 \\\r\n",
        "    --output_dir tests/FULLTESTS/classic --all_datasets \\\r\n",
        "    --reinit_pooler --normalize --mixout_layers 12 --mixout .3 \\\r\n",
        "    --trials 10''' > sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjWX1NsPYg2"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLlHIloufYic"
      },
      "source": [
        "!sh sample_commands/run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq7XJW3wasQY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}